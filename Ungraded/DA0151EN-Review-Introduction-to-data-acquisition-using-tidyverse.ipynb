{"cells":[{"cell_type":"markdown","metadata":{},"source":["<center>\n","    <img src=\"https://gitlab.com/ibm/skills-network/courses/placeholder101/-/raw/master/labs/module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n","</center>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Introduction to Data Acquisition using Tidyverse</h1>\n","\n","Estimated Time Needed: <strong>30 min</strong>\n","\n","<h3>Welcome!</h3>\n","\n","<p>\n","In this section, you will learn how to approach data acquisition in various ways, and obtain necessary information about the dataset. By the end of this lab, you will successfully load the data into Jupyter Notebook, and gain some fundamental insights via the Tidyverse library.\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Table of Contents:\n","\n","*   [1. Data Acquisition](#cell1)\n","*   [2. Basic Insights of the Dataset](#cell2)\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"cell1\"></a>\n","\n","<h1 id=\"data_acquisition\">1. Data Acquisition</h1>\n","<p>\n","There are various formats for a dataset like .csv, .json, .xlsx, etc. The dataset can be stored in different places, on your local machine or sometimes online. In this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n","\n","In our case, the <a href=\"https://developer.ibm.com/exchanges/data/all/airline/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01\">Airline Dataset</a> is an online source, and it is in CSV (comma separated value) format. Let's use a smaller subset of the original dataset as an example to practice data reading.\n","\n","<ul>\n","    <li>data source: <a href=\"https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/lax_to_jfk.tar.gz?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01\" target=\"_blank\">https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/lax_to_jfk.tar.gz</a></li>\n","    <li>data type: csv</li>\n","</ul>\n","\n","The Tidyverse library is a useful tool that enables us to read various datasets into a data frame; our Jupyter notebook platforms have a built-in <b>Tidyverse library</b> so that all we need to do is import Tidyverse without installing.\n","\n","</p>\n","\n","However, if you decide to run this on your local machine, you can use the below line of code to install Tidyverse before loading.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment to install tidyverse if running locally\n","# install.packages(\"tidyverse\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load tidyverse\n","library(tidyverse)"]},{"cell_type":"markdown","metadata":{},"source":["The Tidyverse library has a suite of packages that all work together well, namely:\n","\n","*   tidyr: helps create tidy data\n","*   dplyr: manipulates and transforms data\n","*   readr: easily read different types of datasets\n","*   purrr: functional programming toolkit\n","*   ggplot2: create plots and visualizations\n","\n","In this notebook, we will mainly use functions from readr and dplyr. However, don't worry about memorizing which function is from which library, just know that all are included in Tidyverse.\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Read Data</h2>\n","<p>\n","We use the function <code>readr::read_csv()</code> to read csv files. The <code>::</code> tells you which package the function is from, so <code>read_csv()</code> is from library <code>readr</code> (which is automatically loaded with Tidyverse). There are a few parts to the function to go over:\n","</p>\n","\n","*   `file` (or the first parameter): this is file path along with quotation marks, so that `read_csv()` will read the file into a data frame from that address. The file path can be either an URL or your local file address.\n","*   `col_names`: by deafult this is set to `col_names = TRUE`. If this is TRUE then the first row is set as the headers (which is correct in this dataset).\n","*   `col_types`: used to specify what types columns are. By default, `read_csv()` will guess the type of the columns but if there are columns you want to specify you can do so as well.\n","    *   Posible types you could use are `col_logical()`, `col_integer()`, `col_number()`, `col_character()`. You can look at the documentation of `readr::cols` for more.\n","\n","You can assign the loaded dataset to any variable name, here it is `sub_airline`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# url where the data is located\n","url <- \"https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/lax_to_jfk.tar.gz\"\n","# download the file\n","download.file(url, destfile = \"lax_to_jfk.tar.gz\")\n","# untar the file so we can get the csv only\n","untar(\"lax_to_jfk.tar.gz\", tar = \"internal\")\n","# read_csv only \n","sub_airline <- read_csv(\"lax_to_jfk/lax_to_jfk.csv\",\n","                     col_types = cols(\n","                      'DivDistance' = col_number(),\n","                      'DivArrDelay' = col_number()\n","                      ))"]},{"cell_type":"markdown","metadata":{},"source":["After reading the dataset, there are a few functions you can use to get some initial information about the dataframe:\n","\n","*   `head(dataframe, n)`: returns the first *n* rows of the dataframe, if *n* is not specified, then by default the first 6 rows (not including the column headers) are returned\n","*   `tail(dataframe, n)`: returns the last *n* rows of the dataframe, if *n* is not specified, then by default the last 6 rows are returned.\n","*   `colnames(dataframe)`: retrieves the column names of the dataframe\n","*   `dim(dataframe)`: retrieves the dimension (number of rows and columns) of the dataframe\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show the first n = 3 rows\n","head(sub_airline, 3)"]},{"cell_type":"markdown","metadata":{},"source":["Or, you can choose to not input `n`, then it will show the first or the last 6 rows as default.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show the first 6 rows\n","head(sub_airline)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show the last 6 rows\n","tail(sub_airline)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n","<h1> Question #1: </h1>\n","<b>Check the last 10 rows of data frame \"sub_airline\".</b>\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary>Click here for the solution.</summary>\n","\n","```r\n","tail(sub_airline, 10)\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess Data\n","\n","Throughout this course, we are going to be focusing on flights from  LAX to JFK and predict the possibility of Amy's flight delays. So we also exclude flights that got cancelled or diverted. The previous example uses the final subset dataset `sub_airline`. However, there was some preprocessing done on the original dataset to get there. You can find the full dataset here: [https://developer.ibm.com/technologies/artificial-intelligence/data/airline/](https://developer.ibm.com/technologies/artificial-intelligence/data/airline/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01).\n","\n","From this original dataset, we will show you how we got the `sub_airline` dataset. After downloading the original data with `download.file()` and reading the file with `read_csv()`:\n","\n","1.  Firstly, we use `dplyr::filter()` to filter out all flights from `LAX` to `JFK`, and filter out the cancelled and diverted flights.\n","2.  Then, we use `dplyr::select()` to select the columns by a pre-determined headers list. The original dataset contains more than 100 columns, so we are only going to use a few of the columns such as `Month`, `DaysOfWeek`, `FlightDate`, `Reporting_Airline`, and so on.\n","\n","The below code is to show you how to subset a big dataset. The code is here for your reference. Feel free to play around with it and modify the columns. Remember **not** to run the below code in Skills Network Labs. The data size too big and it is better run to run locally so that Skills Network Labs does not freeze or lag.\n"]},{"cell_type":"raw","metadata":{},"source":["# THIS CELL TAKES LONGER TO RUN\n","# PLEASE RUN THIS LOCALLY, OR IT MAY FREEZE YOUR SKILLS NETWORK LABS KERNEL\n","# Download 2 million dataset\n","\n","# url where the data is located\n","url <- \"https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/airline_2m.tar.gz\"\n","\n","# download the file\n","download.file(url, destfile = \"airline_2m.tar.gz\")\n","\n","# untar the file so we can get the csv only\n","untar(\"airline_2m.tar.gz\")\n","\n","# read_csv only \n","airlines <- read_csv(\"airline_2m.csv\",\n","                     col_types = cols(\n","                      'DivDistance' = col_number(),\n","                      'Div1Airport' = col_character(),\n","                      'Div1AirportID' = col_character(),\n","                      'Div1AirportSeqID' = col_character(),\n","                      'Div1WheelsOn' = col_character(),\n","                      'Div1TotalGTime' = col_number(),\n","                      'Div1LongestGTime' = col_number(),\n","                      'DivReachedDest' = col_number(),\n","                      'DivActualElapsedTime' = col_number(),\n","                      'DivArrDelay' = col_number(),\n","                      'Div1WheelsOff'= col_character(),\n","                      'Div1TailNum' = col_character(),\n","                      'Div2Airport' = col_character(),\n","                      'Div2AirportID' = col_character(),\n","                      'Div2AirportSeqID' = col_character(),\n","                      'Div2WheelsOn' = col_character(),\n","                      'Div2TotalGTime' = col_number(),\n","                      'Div2LongestGTime' = col_number(),\n","                      'Div2WheelsOff' = col_character(),\n","                      'Div2TailNum' = col_character()\n","                      ))\n","# We are going to be focusing on flights from  LAX to JFK and we will exclude\n","# flights that got cancelled or diverted\n","# we are also going to get only useful columns\n","sub_airline <- airlines %>% \n","  filter(Origin == \"LAX\", Dest == \"JFK\", \n","         Cancelled != 1, Diverted != 1) %>% \n","  select(Month, DayOfWeek, FlightDate, \n","         Reporting_Airline, Origin, Dest, \n","         CRSDepTime, CRSArrTime, DepTime, \n","         ArrTime, ArrDelay, ArrDelayMinutes, \n","         CarrierDelay, WeatherDelay, NASDelay,\n","         SecurityDelay, LateAircraftDelay, DepDelay, \n","         DepDelayMinutes, DivDistance, DivArrDelay)"]},{"cell_type":"markdown","metadata":{},"source":["Print and recheck our subset airline data using `dim()` on `sub_airline`.\n"]},{"cell_type":"markdown","metadata":{},"source":["This subset dataframe should include 2855 rows and 21 columns.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check dimensions of the dataset\n","dim(sub_airline)"]},{"cell_type":"markdown","metadata":{},"source":[" <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n","<h1> Question #2: </h1>\n","<b>Find the name of the columns of the dataframe</b>\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary>Click here for the solution.</summary>\n","\n","```r\n","colnames(sub_airline)\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Save Dataset</h2>\n","<p>\n","Correspondingly, \"readr\" enables us to save the dataset to csv by using the <code>write_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n","</p>\n","<p>\n","For example, if you wanted to save the dataframe <b>sub_airline</b> as <b>lax_to_jfk.csv</b> to your local machine in the current directory, you can use the syntax below:\n","</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["write_csv(sub_airline, \"lax_to_jfk.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Read/Save Other Data Formats</h2>\n","\n","We can also read and save other file formats, we can use similar functions to **`read_csv()`** and **`write_csv()`** for other data formats, the functions are listed in the following table:\n"]},{"cell_type":"markdown","metadata":{},"source":["| Data Format |      Read      |            Save |\n","| ----------- | :------------: | --------------: |\n","| csv         |  `read_csv()`  |   `write_csv()` |\n","| tsv         |  `read_tsv()`  |   `write_tsv()` |\n","| delimiter   | `read_delim()` | `write_delim()` |\n","| ...         |       ...      |             ... |\n","\n","You can find more functions from the \"readr\" documentation [here](https://readr.tidyverse.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01).\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"cell2\"></a>\n","\n","<h1 id=\"basic_insight\">2. Basic Insights of the Dataset</h1>\n","<p>\n","After reading data into a dataframe, it is time for us to explore the dataset a little more.<br>\n","There are several ways to obtain essential insights of the data to help us better understand our dataset.\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data Types\n","\n","Data has a variety of types.\n","\n","The main types stored in R are: `numeric`, `integer`, `complex`, `logical`, `character`. In order to better learn about each attribute, it is always good for us to know the data type of each column.\n","\n","Let's check by using `sapply()` to apply  `typeof` to every column in the dataframe `sub_airline`:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sapply(sub_airline, typeof) "]},{"cell_type":"markdown","metadata":{},"source":["**Numeric and Integer Types**\n","\n","Decimal values are called `numeric` in R. It is the default computational data type. If we assign a decimal value to a variable x as follows, x will be of numeric type.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = 10.5       # assign a decimal value \n","class(x)       # print the class name of x, which should be numeric"]},{"cell_type":"markdown","metadata":{},"source":["Furthermore, even if we assign an integer to a variable k, it is still being saved as a numeric value.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["k = 1          # assign an integer value \n","class(x)       # print the class name of x, which should be numeric"]},{"cell_type":"markdown","metadata":{},"source":["In order to create an integer variable in R, we invoke the integer function. We can be assured that y is indeed an integer by applying the is.integer function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = as.integer(3)        # assign a integer value \n","class(y)                 # print the class name of y, which should be integer"]},{"cell_type":"markdown","metadata":{},"source":["**Complex Type**\n","\n","A complex value in R is defined via the pure imaginary value $i$ (`0i` in R).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z = 0i\n","class(z)"]},{"cell_type":"markdown","metadata":{},"source":["**Logical Type**\n","\n","A logical value is often created via comparison between variables, such as True, False.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["logical_values = c(TRUE, T, FALSE, F)\n","class(logical_values)"]},{"cell_type":"markdown","metadata":{},"source":["**Character Type**\n","\n","A character object is used to represent string values in R.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class('this is a character')"]},{"cell_type":"markdown","metadata":{},"source":["## Dplyr for Data Wrangling and Transformation\n","\n","The dplyr package is very useful to transform data and get basic insights from the dataset. The most important functions are:\n","\n","*   `select()`\n","*   `filter()`\n","*   `summarize()`\n","*   `arrange()`\n","*   `mutate()`\n","*   `group_by()`\n"]},{"cell_type":"markdown","metadata":{},"source":["### Pipe\n","\n","Before we dive deeper into using some of the functions of dyplr, we first introduce the **pipe** operator **`%>%`**. The pipe operator allows us to chain together dplyr data wrangling functions.\n","\n","An advantage of using pipe is that it replaces having messy nested functions that can be difficult to interpret like:\n"]},{"cell_type":"raw","metadata":{},"source":["summarize(group_by(filter(sub_airline, Month == 1), Reporting_Airline), avg_carrier_delay = mean(CarrierDelay, na.rm = TRUE))"]},{"cell_type":"markdown","metadata":{},"source":["The same code can be written using pipe and makes it much easier to understand:\n"]},{"cell_type":"raw","metadata":{},"source":["sub_airline %>% \n","  filter(Month == 1) %>%\n","  group_by(Reporting_Airline) %>%\n","  summarize(avg_carrier_delay = mean(CarrierDelay, na.rm = TRUE))"]},{"cell_type":"markdown","metadata":{},"source":["When interpreting the above lines of code, the pipe operator can be read as “then”.\n","The **`%>%`** operator allows us to go from one step in dplyr to the next easily, so the above example can clearily be interpreted as:\n","\n","*   **`filter`** our data frame for month 1 *then*\n","*   **`group_by`** the reporting airline types *then*\n","*   **`summarize`** the average `CarrierDelay` for each airline. The final output is the average `CarrierDelay` for each `Reporting_Airline` in month 1.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Summarize\n","\n","Now, let's go over some examples using basic dplyr functions with pipe.\n","If we would like to get a statistical summary of a column, such as count, column mean value, column standard deviation, etc., we can use the `summarize()` method (can also use `summarise()`).\n"]},{"cell_type":"markdown","metadata":{},"source":["This method will provide various summary statistics, excluding `NA` (Not Available) values.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# group_by / summarize workflow example\n","sub_airline %>%\n","  group_by(Reporting_Airline) %>%\n","  summarize(avg_carrier_delay = mean(CarrierDelay, na.rm = TRUE)) # use mean value"]},{"cell_type":"markdown","metadata":{},"source":["The statistical metrics can tell the data scientist if there are mathematical issues that may exist in a particular column, such as extreme outliers and large deviations. The data scientist may have to address these issues later. The above example used `mean()` to return the mean value of arrival delay, you may also use `sd` for standard deviation, `median`, etc.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# group_by / summarise workflow example\n","sub_airline %>%\n","  group_by(Reporting_Airline) %>%\n","  summarize(sd_carrier_delay = sd(CarrierDelay, na.rm = TRUE)) # use standard deviation"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n","<h1> Question #3: </h1>\n","\n","Using `sub_airline`, get the mean of `ArrDelay` for each `Reporting_Airline`.\n","In other words, group by `Reporting_Airline` and summarize the mean of `ArrDelay` of each reporting airline. Remember to use `na.rm = TRUE`.\n","\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary>Click here for the solution.</summary>\n","\n","```r\n","sub_airline %>%\n","  group_by(Reporting_Airline) %>%\n","  summarize(airline_Delay = mean(ArrDelay, na.rm = TRUE))\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Glimpse\n","\n","Another method you can use to check your dataset is:\n"]},{"cell_type":"raw","metadata":{},"source":["glimpse()"]},{"cell_type":"markdown","metadata":{},"source":["It provide a concise summary of your DataFrame.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# look at the info of airline dataset\n","glimpse(sub_airline)"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","Here we are able to see the information of our dataframe, it prints out column names, column types, and first few values for brief data previews. It also shows us this subset dataset has 2,855 rows and 21 columns. \n","</p>\n","\n","This subset dataset `sub_airline` (\"lax_to_jfk.csv\") will be used throughout the course.\n"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Excellent! You have just completed the  Introduction  Notebook!</h1>\n"]},{"cell_type":"markdown","metadata":{},"source":["### About the Authors:\n","\n","This notebook was written by [Yiwen Li](https://developer.ibm.com/profiles/yiwen.li/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01) and [Gabriela De Queiroz](https://developer.ibm.com/profiles/gdq/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01).\n","\n","<p><a href=\"https://www.linkedin.com/in/yiwen-li-47a019119/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01\" target=\"_blank\">Yiwen Li</a> has approximately three year experiences in big tech industry. Currently, she is a developer advocate, a data scientist, a product manager at IBM, where she designs and develops data science solutions and Machine Learning models to solve real world problems. She has delivered talks this year in JupyterCon, PyCon, Pyjamas, CrowdCast.ai, Global AI on Tour 2020 and Belpy 2021 with hundreds of attendants per talk. \n","\n","<a href=\"https://www.linkedin.com/in/gabrieladequeiroz/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork21582452-2021-01-01\" target=\"_blank\">Gabriela de Queiroz</a> is a Sr. Engineering & Data Science Manager at IBM where she manages and leads a team of developers working on Data & AI Open Source projects. She works to democratize AI by building tools and launching new open source projects.\n","She is the founder of AI Inclusive, a global organization that is helping increase the representation and participation of gender minorities in Artificial Intelligence. She is also the founder of R-Ladies, a worldwide organization for promoting diversity in the R community with more than 190 chapters in 50+ countries.\n","She has worked in several startups and where she built teams, developed statistical models, and employed a variety of techniques to derive insights and drive data-centric decisions\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright © 2021 IBM Corporation. All rights reserved.\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.0.3"}},"nbformat":4,"nbformat_minor":4}